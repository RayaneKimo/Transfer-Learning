{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center><h2> Transfer learning for NLP</h2></center>\n",
        "\n",
        "<br><br>\n",
        "In this work I will:\n",
        "* Implement and pretrain a language model with transformer architecture.\n",
        "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
        "* Compare the performance of the pretrained model to a model trained from scratch.\n",
        " <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "## __The Model__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__The next code implements a transformer-based model for text classification. It allows for the transfer learning of the transformer model on a specific classification task by adding a classification head on top of the pretrained transformer__"
      ],
      "metadata": {
        "id": "FOUbcTp1da83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        # The encoder\n",
        "        self.encoder = nn.Embedding(ntoken, nhid)  # We initialise the embedding matrix representing our vocab as a (ntoken, nhid) dimension\n",
        "        self.pos_encoder = PositionalEncoding(nhid, dropout)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(nhid, nhead, nhid, dropout=dropout) # we define the architecture of one encoder layer with a dropout in order to freeze some random weights from adjusting during the training process.\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)  # we stack the encoder layers\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask): # pass the input throw the \"Base model\"\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src)\n",
        "        output= self.transformer_encoder(src, src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):  # Define the specific classification head\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses) # Pass the transformer results in order to predict the class as output\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "class Model(nn.Module): # We stack all together\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout)\n",
        "        self.classifier = ClassificationHead(nhid, nclasses)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        x = self.base(src, src_mask) # pass throw the \"Base model\" for meaning assessing and textual relationships gathering\n",
        "        output = self.classifier(x) # get output from the previous body and guess the class with the classification head\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__The next class provides a way to add positional encodings to input sequences, which is essential for capturing the sequential order of tokens in transformer models. The positional encodings are added to the input embeddings before feeding them into the transformer model.__\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GXH7C9Xgd5V2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "__Let's verify if our model works, by applying one inference step__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rhb2gkUhJMR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f71dd1-870f-46dc-e8d1-85a3dea91fd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ]
        }
      ],
      "source": [
        "ntokens = 100 # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__The shape is right because when we perform a Language modeling task, the classifier take vector of length \"nhid\" and try to guess the next work by predicting probabilities over all the vocabulary of size \"ntokens\". Then we just take the index of the max__"
      ],
      "metadata": {
        "id": "ajGl10jZWPgk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## __Vocabulary and Tokenization__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ___Dowload the vocabulary___"
      ],
      "metadata": {
        "id": "ZyE6zgIdehay"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qjd26ghWuff"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__In the next code we will prepare the vocabulary file, extracts information from it to create mappings between tokens and indices, and prints a token for verification purposes.__"
      ],
      "metadata": {
        "id": "XrHGKfkrezTs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vFdH_-JeFbGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d15ba90-1556-4e73-e928-e0c7bb468475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁d\n"
          ]
        }
      ],
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "ind2token = {}\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for index, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        # token to index\n",
        "        token2ind[word] = index + 4 # We index our vocab starting from the 4th index. This is used in order to encode the sentence for the feed forward\n",
        "\n",
        "# index to token\n",
        "ind2token = {v: k for k, v in token2ind.items()}  # This is used for decoding a sentence.\n",
        "\n",
        "print(ind2token[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "## __Data Loader__\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Now we define a PyTorch dataset class and data loader for our NLP tasks, specifically for language modeling and classification. The dataset reads text documents and, if applicable, corresponding labels from files. It tokenizes the input sequences, processes them based on the specified task, and provides the data in batches using PyTorch's DataLoader.__"
      ],
      "metadata": {
        "id": "UDqkj3MwfcGJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # tokenize the input document\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "\n",
        "\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]] #start our input with an sos\n",
        "        for token in sequence: # for each token\n",
        "            if token in self.token2ind: # if it is defined in our vocabulary\n",
        "                source_sequence.append(self.token2ind[token])  # we append it to the tokenised sequence\n",
        "            else:\n",
        "                source_sequence.append(self.token2ind[\"<oov>\"]) # else if we don't found the token we note as it is out of vocab\n",
        "\n",
        "\n",
        "        # target construction\n",
        "\n",
        "        if self.task == \"language_modeling\": # In this task we shift our output to the right in order to predict the next word based on the previous ones\n",
        "            target = source_sequence[1:] # shift right without taking the <sos>\n",
        "            target.append(self.token2ind[\"<eos>\"]) # add the end of sentence\n",
        "\n",
        "        elif self.task == \"classification\": # In this task the label would be the binary review classes\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## __Training for Language Modeling task__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Defining the train function designed for training a neural network model, particularly suited for our use case natural language processing tasks like language modeling or classification__"
      ],
      "metadata": {
        "id": "6cjD6PW1gIEX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): # iterate over the data loader\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) # Feed forward\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            output = output[-1]\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target = data[1]\n",
        "        target = target.to(device)\n",
        "        loss = criterion(output, target) # Compute the loss on both prediction and the ground truth\n",
        "        loss.backward() # Feed backward the error for weight adjustment\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "outputs": [],
      "source": [
        "# vocab size\n",
        "ntokens = len(token2ind)\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device) # initialise a language modeling model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "outputs": [],
      "source": [
        "# optimization paramerters\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwh3n9xZQy4e"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0m11g4ScjZaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63fcc8c-201f-4e86-9894-40b722c2343f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 10.77388 | ppl 47757.099\n",
            "| epoch   1 |  1000/ 3125 steps | loss 9.96632 | ppl 21296.896\n",
            "| epoch   1 |  1500/ 3125 steps | loss 9.38593 | ppl 11919.496\n",
            "| epoch   1 |  2000/ 3125 steps | loss 9.04643 | ppl 8488.157\n",
            "| epoch   1 |  2500/ 3125 steps | loss 8.79955 | ppl 6631.271\n",
            "| epoch   1 |  3000/ 3125 steps | loss 8.65075 | ppl 5714.426\n",
            "| epoch   2 |   500/ 3125 steps | loss 8.52672 | ppl 5047.856\n",
            "| epoch   2 |  1000/ 3125 steps | loss 8.42826 | ppl 4574.522\n",
            "| epoch   2 |  1500/ 3125 steps | loss 8.35164 | ppl 4237.114\n",
            "| epoch   2 |  2000/ 3125 steps | loss 8.30418 | ppl 4040.735\n",
            "| epoch   2 |  2500/ 3125 steps | loss 8.25864 | ppl 3860.836\n",
            "| epoch   2 |  3000/ 3125 steps | loss 8.18930 | ppl 3602.191\n"
          ]
        }
      ],
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\",\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## __Text Generation__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BcBC6FSkMH3"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt')\n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Using \"SentencePiece\", a library for subword tokenization, by loading a pre-trained French model, try to encode a sample sentence into subword pieces, and then decoding it back to the original form.__"
      ],
      "metadata": {
        "id": "DJg3-8dsiFrf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBRRVsWqlIoQ"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece   # uncomment this if you are using google colab\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "outputs": [],
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind[\"<sos>\"]] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind = torch.argmax(out[-1, :, :], dim=1)\n",
        "\n",
        "    return next_token_ind, out\n",
        "\n",
        "\n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    generated_tokens = sent # create the varibale to store the whole sentence progressively\n",
        "    for _ in range(max_len):\n",
        "        infered_ind, out = infer_next_token(generated_tokens) # make an inference\n",
        "        next_token = ind2token[infered_ind.item()] #\n",
        "        next_token = s.decode_pieces([next_token]) #stringify the next token\n",
        "        if next_token == \"<eos>\":\n",
        "            break  # Stop generation\n",
        "\n",
        "        generated_tokens += \" \" + next_token # add the generated token to append the sentence\n",
        "\n",
        "    return print(generated_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "f83Nn5nSly4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb49adc-2c1a-46f5-86a7-72e4b5c09157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cette maîtresse a été tuée par le jeune homme .\n"
          ]
        }
      ],
      "source": [
        "sent = \"Cette maîtresse\"\n",
        "infer_next_tokens(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### __Supervised task__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Data for a classification task is being downloaded from the specified URLs__"
      ],
      "metadata": {
        "id": "lhUPhc7TjejP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K1BZsblmEmx"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "outputs": [],
      "source": [
        "# evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader): # this puts the model on the evaluation mode by turning off some features like dropout\n",
        "    model.eval() #\n",
        "    total_acc = 0\n",
        "    total_count = 0\n",
        "    for idx, data in enumerate(data_loader): # iterate over batches\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )  # generate a mask\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) # make an inference\n",
        "        output = output[-1] # take the last vector\n",
        "        output = torch.argmax(output, dim=1) # grid search: taking the index with the max probability over the dim 1 (0 for the batches)\n",
        "        target = data[1]\n",
        "        target = target.to(device)\n",
        "        acc = torch.sum(output == target).item() # take the correct predictions\n",
        "        total_acc += acc\n",
        "        total_count += len(target)\n",
        "    return total_acc / total_count\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "outputs": [],
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-xclMCpnVpw"
      },
      "outputs": [],
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RCpBIdTHojm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "5e0c6317-73cb-4bc2-e6de-8bde91d19f20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7edff3793370>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnuElEQVR4nO3dd3hUZdrH8e9k0jshpEEg9N4MgiAKKgrWZV0VfRWUVVxZUJC1oQu6a2FtiK4FdXXVXVdRV10ripEiShNEQCEJNbQkhJJK2sx5/ziZiZGWNnMmye9zXXMxmTlz5p6QZO55nvu5H5thGAYiIiIiPszP6gBERERETkUJi4iIiPg8JSwiIiLi85SwiIiIiM9TwiIiIiI+TwmLiIiI+DwlLCIiIuLzlLCIiIiIz/O3OoDG4HQ62bdvHxEREdhsNqvDERERkVowDIPCwkKSkpLw8zv5GEqzSFj27dtHcnKy1WGIiIhIPezevZt27dqd9JhmkbBEREQA5guOjIy0OBoRERGpjYKCApKTk93v4yfTLBIW1zRQZGSkEhYREZEmpjblHCq6FREREZ+nhEVERER8nhIWERER8XlKWERERMTnKWERERERn6eERURERHyeEhYRERHxeUpYRERExOcpYRERERGfp4RFREREfJ4SFhEREfF5SlhERETE5zWLzQ+lmao4Cju/hX3roMOZkHKm1RGJiIhFlLCIbzm0A7Z+BZlfwo5voPJo9X1dRsF590NiP+viExERSyhhEWtVlsGubyGzKkk5mFnz/si2kNAPti4yE5mtX0GfK+Dc+yCmkzUxi4iI1ylhEe87kgWZi8zLjmVQUVx9n58/JJ8BXc83L3G9wGaDg9tg8SOw6T3z8vOHkDoRRtwF4XGWvRQREfEOm2EYhtVBNFRBQQFRUVHk5+cTGRlpdTjya5XlsHulOYKSuQgObKl5f3hCdYLSaSQER534XPt/hK/+AtvSzK8DwmDoH2HYbRCs/3sRkaakLu/fSljEM/L3mtM4mYtg+xIoL6q+z+YHyUPMBKXL+ZDQ1xxFqYsdy+CrB2DvWvPrkBg4+w4YdCMEBDfWqxAREQ9SwiLe56iA3aurR1Fyf6p5f1icWTTb9XzofA6EtGr4cxoGbP4Y0v5aXfsSlQwjZ0L/q8HP3vDnEBERj1HCIt5RmF29omfbYigr+MWdNmh3evVUT0J/8PNQ2x9HJfz4H1g8Bwr3mbe16QHnzYbuF9V99EZERLxCCYt4hqMS9n5fVTD7JWRvqHl/aOuqUZQLoPO5EBrj3fgqjsLql+CbuVB6xLwteQiMegA6DPNuLCIickp1ef+u10fe5557jpSUFIKDgxkyZAirV68+6fHz5s2je/fuhISEkJyczO23305paWmDzileUlEKP74N7/0eHu8Mr46Gb56oSlZs0DYVRtwDN30Nd2TC5S9B3yu8n6wABITAmdNg2o8wfAb4h8DuVfDPC+HNqyB7k/djag4Ks2HXCigvsToSEWnB6jzCsmDBAiZMmMD8+fMZMmQI8+bN49133yU9PZ24uGOXl/7nP//h97//Pa+++irDhg0jIyODG264gauvvpq5c+fW65y/phEWD/rsLlj9YvXXwdG/qEU5D8LbWBbaKRXsh2WPwdrXwXAANuh3FZxzL7RKsTo63+aoNEfR1r0BmV+A4QR7oDli1WkEdDoXkgaoTkhEGsSjU0JDhgzh9NNP59lnnwXA6XSSnJzMrbfeyj333HPM8VOnTmXz5s2kpaW5b/vTn/7EqlWrWL58eb3O+WtKWDykshye7AZHD8PgP5gjJ21Tm96b1MFt8PWD8NMH5td+ATDo93D2nb6dcFnh4Db44d+w/j9QlF19e2gslOTVPDY4ClLOMouoO51jNvJTvZCI1EFd3r/r1DiuvLyctWvXMnPmTPdtfn5+jBo1ihUrVhz3McOGDePf//43q1evZvDgwWzfvp3PPvuM8ePH1/ucZWVllJWVub8uKCg47nHSQFu/MpOV8AQYM6fpJSourTvDla+Z00Vf/QW2LzZHjX74NwybCkOntuweLhVHzdVW696And9U3x4aCwP+DwaOh9iucGg7bPvaXKa+4xsozYctn5gXMFdodRpZfQmL9f5rEZFmq04JS15eHg6Hg/j4+Bq3x8fHs2XLluM+5v/+7//Iy8tj+PDhGIZBZWUlt9xyC/fee2+9zzlnzhz+8pe/1CV0qY8NC8x/+17RdJOVX0oaCBM+NN9wv3oA9v0ASx+FNf8wR1sG/R78gywO0ouyN5pJyoYFZvIBgM2c8jttAnQbA/6B1ce37mxeBk8yp4z2rzeTv+1LIWsl5O+GH/5lXsDsr9NppDn60n4oBIZ6+QWKNBNOB2StMKdlY7tBSLTVEVnC4635lyxZwiOPPMLzzz/PkCFD2Lp1K9OmTePBBx9k1qxZ9TrnzJkzmTFjhvvrgoICkpOTGytkAfMNLP1z83q/q6yNpbF1GgmTFsPP/zOnig5uhYX3wIrnzfqWflc1jwTteEoLzK0N1r1hJmwuUcnmSMqA/4PoWvwu2f2h3SDzcvadUF5sFuZuX2wmhDmbzIQoeyN89/fq+pfO55jf/8QBzfd7LNJYDMOsJfvqLzV7W0UkQpvuZvsG96W7NYsdvKhOCUtsbCx2u52cnJwat+fk5JCQkHDcx8yaNYvx48dz0003AdC3b1+Ki4u5+eabue++++p1zqCgIIKCWtAnYSts/hgcZeYvQkIz3B3ZZoPeY6HHxebU0NJHIT8LPrwFvnvG3BW62+jmUZNhGOZqqXVvmHU8FVWrffwCzNd/2gQziWhIAhEYBl1HmReAolyzG/G2xWYSU7DXnG7a+Y3Z6C84GjqeXT19pPoXkZqyVpkjwVnfmV8HRUJguNlrqnC/edm+pOZjwuJ+kcj8IqEJi20Wv191SlgCAwNJTU0lLS2NsWPHAmaBbFpaGlOnTj3uY0pKSvD7VcMwu938w2gYRr3OKV7gng66sln8oJ+QPQAGTYR+48y6luVPQe7P8NY4cxPG8/8C7c+wOsr6KToAP75lJiq/3AW7TQ8zSek3znN1JuFx5lRi3yvMhOngturRlx3LzD45mz8yLwDR7auTl44jIay1Z+KqD8MwV0lpREi8IXezmdSnf2Z+7R8Mg2+G4bebIyil+XAgw9yT7cAWOJBuXvKzoDjXvPyyFg3MrUtqJDFV/0YkNKm/7/Va1nz99dfz4osvMnjwYObNm8c777zDli1biI+PZ8KECbRt25Y5c+YA8MADDzB37lxeeukl95TQ5MmTSU1NZcGCBbU656lolVAjK9gHc3sBBkzbAK06WB2R9xw9bCYtq16EyqpeQd0uNJOa1l3MN1Z7gLUxnozTYY5qrHvd/IPnrDRvDwiFPpfDadebHYit/CPlqDSno7YvMZOY3avBWVHzmIR+ZvLSuar+JSDkxOczDLNwuKLEvJSXVF+vOGpOV1UcNXcFrzj6q/tdx5/o/qrHGw6ztueChyGuhye/O9JSHckyu3X/+BZgmHuuDbzO7HMV1fbUjy8rgryMqgTGlchshsO7zPMdT1BUVfLSvebUUlQ7r/2N8Hin22effZbHH3+c7OxsBgwYwDPPPMOQIUMAGDlyJCkpKbz22msAVFZW8vDDD/Ovf/2LvXv30qZNGy699FIefvhhoqOja3XOxnzBUgvfPgOLZkH7YfD7z62OxhoF+2DJ38zpIsNRfbvNbiYtrTtDTOfqf2M6QnQHs7bDCkeyzFh/eBMK9lTf3jbVHE3pfbnvroQqKzILCrdVjcD8eh8qexC0Pc383p8o6fAWmx1OvwlG3tPs6wXES4oPwjdPwpqXwVFu3tbzMjh3FrTp1vDzl5eYI6w1Epkt5qo/w3n8xwSGm8W9vx6Vie7Q6FusqDW/NMwLwyFnI1zylLlypiXLyzRHXPatN3/BK4+e+Fg/f/MXukYy09G8Ht2+8acUKsvMUZR1b5hv9q5PUSGtoN/VcNp4iO/duM/pDYU5sGOpmbxsW1y9P1Rt+Aebo0kBoeaqpIAQCAgz/w0Mrb7vuPdX/Vvj/qpL6RFIexDSPzWfJ6QVnHMfpE60Lkn1pn3rzU/vQRFm/x3XJSjSvK0JTSv4jLIiWPm8+QGxvNC8LeUsGPUXaJfq+eevLDMXHPwyiTmQbt7mGpn9Nf8QuDPT/D9vJEpYpP5yfoYXhpoFmXdk6FPkLzmdZqHboW1mTcah7ebl4DY4vKN6Cul4/ALM7rqtO5sFpjGdqhObqHZ1S2Zyt5hLh398C0oOVt/ecYQ5mtLjEggIrvfL9CmGYSaN+9ebU3EnSzgCQj23wabL9iWwcKZZ5wTQpieMecTcO6s5yloFS/9m9t85EZufmbgER5mjeMHRNROaXyY4wZHHJjzBUS2rPqiy3JyyXfqYWW8C5hToqAfMnyOrkz9Hhfl37ZeJTO4Wc5QmJAbuSG/Up1PCIvX31QPmiEKPS+DqN62OpulwOs2VMIe2H5vQHNphrrg6EXsgtOr4iyTmF8lMZFvzTbisCH7+0BxN2b2q+rERiTDgWnOuO6ajx1+mYNbgrP0nLH4Ejh4yb+t2IYx+2Px/aw52fmuunNux1PzaZjeLzytLzaJP18U1hdFQgREnT2iCoyA83lxZFpnYOM/pbU4nbPovLH4IDu80b2vVEc79szll6+lku6EclVCUU7t6mjpQwiL143TCvL5mDcSVr5vLfqXhnA4zmTm4zUxmDu2ovn5458n/6NuDzEQkf2/1sLHNDt0vNEdTOp/XMqYkfNHRw7DkUbP2wFlpjqIN+QOMuMt8g21qDMNcXbLkUdhlbpuCn7/Zm2f4jGMTYsOoSmAKaiYxZfk1vy7NP84xVV/Xp/4ovq+5l1nX86HdYN//+TcMs2v4V38xp9rBTL5G3GUWwftyEb8XKGGR+tm5HF672PxUc0dm85lW8GVOh9kh1jW15P63Kpn55VxyTCczSen/fxBx6tVz4iUHMuCLe2HrIvPr0Fg4b5bZiK8pTHUYhrlaa+ljZvEzmMnXaePNpbTR7T333JXl1cnLry+/vv3gVti7jhorXoKjzE7KXS8wV3H52u/F7jXmqLUrAQyKNLcIOWOyWTMlSliknj66zZxbHTgefvOs1dGIo7Iqmdlm/qGzejmynFzGl2bi4up5k9AXxvwNUoZbG9eJuD75L30U9qwxb7MHQer15ptqVDtr4zue4jzYmmYmh669zn4psX9V8nK+2YXZqoTxQLrZS8W1z5Y9yNzS4qw/qS7wV5SwSN1VlMIT3czh3Os/NueKRaRuHBWw+mVzSXxZ1f5MPS+DCx40i659gWFAxkIzUXFtz+AfbK54OnNa06kRcTrMEZfML83L/vU17w9pZU6Zdj3fHH3xxmac+Xuqeqn8x1wybPMzp9RGzvTNBNAHKGGRuvv5I3hnvFnkOX2T7xeAifiy4jxY/DCsfc1847IHmTuDD58BQeHWxOR0msvglz4K2RvM2/xD4PQbYdhtvjedUldFueaoS+Yi2Jb2iw09AWxmL58u55sjMEkDG/dvXMkhs5fK6perC+x7XALnzTb7l8gJKWGRultwnbl/0JnT4Py/Wh2NSPOQvQm+mGluRwAQngCj7jf75HjrQ4HTaW6BsOxxc1NKMJeCD54EQ6dCeBvvxOFNjkrY+3316Ev2xpr3h7Y2R126nA9dzqv/NE15cXUvlbIC87YOw80lysmnN+gltBRKWKRujh42p4Mc5XDLt5DQx+qIRJoPw4Atn8KX91UvZ006zaxvaV+7bt714nSYS+GXPm62aAdz+fCQm+GMKb61X5OnFew3R1+2LjKbEbqSCzCnbdoOql55lND/1Mmko6K6l0pR1ca98X3NRKXLeao1qwMlLFI3a1+Dj6dBXG/443dWRyPSPFWWmZ/Glz0B5UXmbX2vNN/kGrO+wVEJP71vjqjkZZi3BUXBGbfAkFtU9OmoMHsZZS4yL7/eCiIszhx96Xq+uZdVSKvq+5xO83v79UNms0gwa5POndU0eqn4ICUsUjf/vNhcdjfqLzB8utXRiDRvhTnw9V/NfZ8wzDqS4dPNOpLA0Pqf11EJG98xE6JD28zbgqNh6BRzt9+Q6IbH3hzl7zVHXjIXmZ2MXckkmD2PkgebCUxMR1g+r7r+JyyuupeKf6AVkTcLSlik9o7shnl9ABvcvkmV7CLesu8Hs82/q/dJZDs4/y/Q53d1m1JwVMCPb8M3T1RPOYW0MutTBt/su5te+qLKcvP/w5XAHNhy7DGBEdW9VKwqoG5GlLBI7X0zF9L+Ym66dcMnVkcj0rIYhjnFsOh+s+cOQPIZMGaOuarlZCrLYf2b5u9wfpZ5W2gsDLvVXPnTiBvUtVhHsqqnjg5shu4Xm71UWlL9j4cpYZHaMQx4fqj5i3jZ380uqiLifRVH4bu/m/t4udrVD7jWXBYbkVDz2Moyc0+p5fPMbTTAnJ448zZzd3V1UJUmRAmL1E72Rpg/3Nx8745MzXGLWC1/r9nKfeM75teB4XDWDHNVD0Z1olK4z7w/PMGsfznt+obVv4hYpC7v3z6+a5R41IYF5r/dxihZEfEFUW3hdy+btScL74a9a80W72tfM0dWXEtoI9ua+/wMHK89v6TFUMLSUjkdsPG/5vV+46yNRURqSj4dbvzKHGn56gGzlgIgKrkqUbkO/IMsDVHE25SwtFQ7l5vDysFRZr8BEfEtfn7Q/2qzxfv3r5r9U/pepSW00mIpYWmpNlTNkff+rT6pifiyoHCzoFakhVNbvpao4qi5twiYn9hERER8nBKWlihjobmXRlQytB9qdTQiIiKnpISlJXJNB/W9UntfiIhIk6B3q5am5JDZtRGgn6aDRESkaVDCciqGAYXZVkfReH76AJwVkNAX4npaHY2IiEitKGE5mUM74JUL4PXLzA3GmgPXdJB6r4iISBOihOVkQlqZ27TnpcOaf1gdTcMd3gm7VwI2c0dYERGRJkIJy8mERMO5s8zri+dAcZ6l4TTYxnfNfzueDZFJ1sYiIiJSB0pYTuW0CWa9R1k+fP2Q1dHUn2FoOkhERJosJSyn4meHCx8zr699DfZvsDScetv/I+RlgH8w9LzU6mhERETqRAlLbXQYBr0vBwxYONMcrWhqXKMr3S+E4JNv4S0iIuJrlLDU1vl/Bf8Q2LUcfv7Q6mjqxumATe+Z1zUdJCIiTZASltqKTobh083rX84y9+NpKnYshaIcc9VT5/OsjkZERKTOlLDUxbDbILId5O+Gb5+xOprac+/MfLm2phcRkSZJCUtdBIbCBX81ry9/CvL3WBtPbZSXwOaPzeuaDhIRkSZKCUtd9b4c2g+DyqOw6H6rozm19M+gvAiiO0DyYKujERERqRclLHVls8GFfwNsZiHrrhVWR3Ry7t4rV5mxi4iINEH+VgfQJCX2h9Trzb4sn98FNy8x+7X4muI82PqVeb2vdmYWkaYnPbuQRxduYeX2gyS3CqVLfDhd48LpGhdB1/hwUlqHEeivz94tgRKW+jp3Fmz6ALI3wA//NhMYX/PTB2A4IHEAtOlmdTQiIrWWW1DK3EUZvPP9bpxVra/ScwpJzymscZzdz0ZK61B3AtOlKpnp1CaM4AAf/CBZTw6ngQ3w82u5I+VKWOorLBZG3g1f3Atpf4XeYyE4yuqoatqwwPxXxbYi0kSUlFfy0rLtvLRsOyXlDgAu7JPAzWd34khJBZm5hWTmFJGZW8TW3CKKyirZdqCYbQeKWfhT9Xn8bNChdVhVAhNO13gzkencJpyQQN9JZJxOg8Ml5eQUlJFTUFp1KSO7oJTcglJyCs2v84rKMAzzdQXY/Qiw++Fvt+Hv50eg3YZ/1dcBfn4E+Ju3B9htVcf5EeBnM+93PdbPfMwxj3VdP+axfgT6+3FZf+v2oVPC0hCDbzanhfIyYOljMPphqyOqdnAb7FkDNj/tzCwNsjg9lw9/2Ev7mFC6xIXTLT6CjrHN69OrWM/hNHhv7W6e/DKD3MIyAAYkR/Pni3syKCXGfdw5PeLc1w3DILug9BcJjJnMZOQUUlBayY68YnbkFbPo5xz3Y2w2aNcqxByRiasakYmPoEtcOOFBjfeWaBgGRWWV7gSk5r/ViUluYSkVjtp3T3caUFbppKzS2Wix1pYSlqbMHgCj58Cbv4NV8yH1BojtanVUpo1VnW07jYSIeEtDkaarwuHkrvc2cKDqDcSlqXx6laZhacYB5ny2mS3Z5nRPckwId4/pwcV9E7GdZLGAzWYjMSqExKgQzu7Wxn27YRgcKCpja1Uik5FTSGZuEZk5hRwuqWD3oaPsPnSUr7fk1jhfUlQwXeLNRKZbfDhd4sxEJiokoMZxpRUOcgvKqkY/SsnOLyW3sOYISU5BqXuEqDZiwwOJjwyuugQRFxFMQlT19bjIIPz9/Kh0OKlwGlRUOql0OqlwGFQ6DModTiodTiqdBhUO1+3HO9b8t8LppNJR89hK5y/O4zCOeazd4ukoJSwN1XUUdBsDGQvN6aFr37U6oqqdmTUdJA23eEsuBwrLiAkLZHTveJ/59CrNw+b9BTzy2Wa+ycwDIDLYn9vO68r4oR0I8q9/4muz2cw3+YhghnWJrXHfwaIyM3nJLWKrK5HJLeJAYRn78kvZl1/KsowDNR4THxlE+5hQCo5WklNYypGSilrHEhHsT0JVIhIXGeS+Hh8ZRFxkMAmRwcSGB6lwuBb0F6QxXPAwbE2DzC8h40vodoG18exdB4e2QUAo9LjE2likSXvn+90AXJHajnsv6gkc++nVVVOwNbeIg8XlJ/z02jY6pMaIzIk+vUrzl1NQypNfpvPu2j0YBgTYbVw/NIWp53YhOtSz3bhbhwfROjyIMzq1rnH7kZJytlYlL+YUUyFbc4vYn+8aMak5yhjk72eOgETUTER+fT00UG+zjUXfycYQ2wXOuAW++zt8MdOchrGyBf5G187MF0FQuHVxSJOWnV/qTjquGpTsvv1Un15df/S3ViUzGTnmp9e9R46y98hRlh7n02vXquTFNbXUNS6cVmHWbiPhdFYPmxugEaJGUFxWyYvLtvPysu0crTCnSy7um8hdY7rToXWYpbFFhwYyKCWmRr0MQEFpBdtyi9h9+CitQgPM0ZGIYCJD/E86XSWNT7+BjeXsu+DHt+HgVlj9Egybak0cjorq+hVNB0kD/HfdHpwGnJ7Sii5xtUt8XZ9eh9Tj0+vyrXk1HhMbHuheopoSG4afjap5dScVlcav5uTNuXr3/HzVHHyl00m5a37e9VhH9dx9ZdUcveux7loAp4HDWbMQcso5nblzdI+GfVNbqEqHk3fX7uHJLzPIKzJHKlI7tOLei3qS2qGVxdGdXGRwAAPbt2Jge9+OsyVQwtJYgiPhvPvho6mw9FGzs2x43Kkf19i2L4GSPAiNhc7neP/5pVlwOg0WrDGng8ad3r7B5zvVp1f3iExVTcGew0fJKyonr+gQK7cfavDzN4Z/rdjFbed1bVBtRUtjGAZLqgpqM3KKAOjQOpR7xvRgTJ8EjVBInShhaUwDroU1/4D96+HrB+Gyv3s/Blcr/j6Xm6uYROph5Y6DZB0qITzIn4v6JnjseU706bW4rJJtB4rcy1V3HyrBZoNAV++Jqt4Q7j4RVf0oAvzNXhKuYwKrbq/Rf8JefUzALx/r7jthc/epCPD3w26zcd6TS8kuKOWbjDxG9dKqu9r4aV8+cz7b4h45iw4N4LZzu3LdGR1UYCr1ooSlMfn5wYWPwasXwLp/waDfQ9JA7z1/WRFs+cS8rukgaQDX6MplA5IsKRoMC/KnX7to+rWL9vpzH89FfRN59dsdfLxhnxKWU9iff5Qnvsjg/R/MgtpAux83nJnClJFdiArVhyipP6W5ja39kKp9ewz4/B5zibG3bPkUKkogphO0TfXe80qzcqSknM83ZQNw9enJpzi6Zbi0fyIAi37O4Wgdemu0JEVllTzxRTrnPLGE/64zk5VL+yeR9qcR3HtRTyUr0mAaYfGEUQ+YIx27V8Km/0LfK7zzvK7VQX21M7PU34c/7KW80kmPhAj6tvWx7SYsMiA5mnatQthz2FyufXG/RKtD8hmVDidvr9nNvK8yyCsqB8xC7Xsv6qlCVWlUGmHxhKi2MHyGeX3RbCgv9vxzFuXCtq/N6/20M7PUj2EYvF01HXT16ckqiqxis9m4tKol+Scb9lkcjW8wDIO0zTmMefob/vzhJvKKyukYG8aL41N55w9DlaxIo9MIi6cMmwo/vAFHsuDbp+Gcez37fJv+C4YT2g6C1p09+1xeYhgGCzdl8+aqLBxOg8gQfyKCA4gMDiAyxL/q3wAigv1r3hYcQHiwv+VtpJuijXvz2ZJdSKC/H2MHtrU6HJ9ySb9EXliyja+35FJYWkFEcMud4ti0N5+HP93Miu0HAWgVGsD0Ud34vyHtCbDrc7B4hhIWTwkIgQsegncmmAnLwOsguuHLQ0/ItTqomYyufLc1j0cXbuHHPfn1PkdEkP/xE5rj3BZxnPtb4h9e1+jKhX0SPN5xtKnplRhJpzZhbD9QzFebc/jtwHZWh+R1+44c5Ykv0nn/h72AuRne78/syOSRndWxWDxOCYsn9bwMUs6Cnd/Al7Pgqtc98zx5mbBvHdjs0PtyzzyHl2zam8+jC7e49xYJDbRz4/COdIkLp7C0koLSCgqOmv8WllZScLSi6rYK9/2lFeYupoVllRSWVdY7lpAAuzuJufy0dkwe2TxGrk6kpLySj9eb0x3jBqnY9tdsNhuX9kvi6bRMPv5xf4tKWApLK3hhyTZeWb7DvUvw2AFJ3DG6O+1ahVocnbQUSlg8yWaDMX+DF8+Cnz+EHd9Ax7Ma/3lcoyudz4XwNic/1kftzCvmiS/T+WTDfsDcW+T/Brdn6rldaRMRVKdzlVU6KCyt/FVCU0lhacVJEh7X/ZUUVSU5RyscHK1wkFNQxuNfbOGivgmWtw/3pM82ZlNYVkn7mNBj9lkR06X9E3k6LZNvMg9wpKS8RYxCOZ0G17y8kk17CwAY0jGG+y7u6TNLzqXlqFfC8txzz/H444+TnZ1N//79+fvf/87gwYOPe+zIkSNZunTpMbdfdNFFfPrppwDccMMNvP56zdGH0aNHs3DhwvqE51sS+kDqRPj+FVh4D/xhGfg1YqdMw6heHdQEe6/kFpTyzNeZvL16N5VOA5sNftM/iRnnd6d96/p9cgvytxMUbic2vG6Jjkulw0lRmZnw5B+tYM7nm/l260FeWradh3/bt17nbAoWrMkCYNzpyfip/ue4usRF0DMxks37C/jip+xG6QLs61buOMimvQWEBdqZd/VARvWMUzG2WKLOk/QLFixgxowZ3H///axbt47+/fszevRocnNzj3v8+++/z/79+92XTZs2YbfbufLKK2scN2bMmBrHvfXWW/V7Rb7o3D9DcDTkbIJ1jTwttGcNHN4JAWHQ46LGPbcHFZRW8PgXWxjx+BL+vTKLSqfByO5t+PTWs5h39cB6JyuNwd/uR3RoIMkxofRpG8Vt53YF4N21e8gtLLUsLk/amlvEmp2H8bOZOzPLiV1StaT54x/3WxyJd7xTVdf0m4FtOb9XvJIVsUydE5a5c+cyadIkJk6cSK9evZg/fz6hoaG8+uqrxz0+JiaGhIQE92XRokWEhoYek7AEBQXVOK5Vq2a0JC40pnqVUNqDcPRw4517wwLz356XQKDvT1eUVjh4adk2zn5sMc8t3sbRCgcD20fz9s1n8NrEwfRKirQ6xGMM7hjDae2jKa908s9vd1odjke8+735pnRO9zjiI4Mtjsa3XdrPXN783bY8DhSWWRyNZ+UfrXA3EbxKdU1isTolLOXl5axdu5ZRo0ZVn8DPj1GjRrFixYpaneOVV17h6quvJiys5pvrkiVLiIuLo3v37kyePJmDBw/WJTTfN+hGaNMTjh6CJY82zjkdFbDpffO6j68OqnQ4eWfNbs55YgmPfLaFIyUVdIkL58Xxqbw/eZhP10zYbDYmj+wCwL9X7KKgtMLiiBpXeaWT/67bA5jTQXJy7VuH0j85GqcBn29q3qMsH/+4j7JKJ93iw+nfTk0ExVp1Sljy8vJwOBzEx9fcSyM+Pp7s7OxTPn716tVs2rSJm266qcbtY8aM4Y033iAtLY1HH32UpUuXcuGFF+JwHL8FdllZGQUFBTUuPs/uD2PmmNdXvwS5Wxp+zq1pZgIUFgcdRzb8fB7g6qUy5ulvuOu/G9ifX0pSVDCPXdGPL6afzejeTWPH1vN6xNE1LpzCskreXJlldTiN6ustOeQVldMmIohzeliww3gTdGnVtNAnzXxayDXydtUgNREU63m10cQrr7xC3759jynQvfrqq7nsssvo27cvY8eO5ZNPPmHNmjUsWbLkuOeZM2cOUVFR7ktychP5VNj5HOhxCRgOswC3ofsMuaaD+vzOTIh8zIptB/nt899xy7/XsjW3iOjQAP58cU++vmMkVw1KblKN3fz8bNwywlzW/MryHZRWNJ/9ZFy9V353WrsW2XumPi7pl4TNBqt3HmJ//lGrw/GILdkF/LgnH38/m5oIik+o01+n2NhY7HY7OTk5NW7PyckhIeHkW9AXFxfz9ttvc+ONN57yeTp16kRsbCxbt2497v0zZ84kPz/ffdm9e3ftX4TVLngQ7IGwfTFkNGAVVGkBpH9mXvex6aCf9uVz/auruebllazffYSQADtTz+nCsrvO4aazOhEc0IirpLzosgFJJEUFk1dUxvvr9lodTqPYd+QoyzIOAJoOqouEqGBO7xADwKcbmucoy7vfm9OE5/WMq/eKO5HGVKeEJTAwkNTUVNLS0ty3OZ1O0tLSGDp06Ekf++6771JWVsZ11113yufZs2cPBw8eJDHx+BuMBQUFERkZWePSZMR0gqFTzOsLZ0JlPYv2tnwClaXQuiskDWy8+Bpg18FibnvrBy5+ZjlLMw7g72dj/BkdWHrXSO4Y3Z3IJt7KPMDux01ndQLgxWXbcDi9uBO3h7y3dg9Ow+yt0THW94u2fYlrB+ePf2x+ewuVVzr5oKqbrRJZ8RV1Hv+dMWMGL7/8Mq+//jqbN29m8uTJFBcXM3HiRAAmTJjAzJkzj3ncK6+8wtixY2ndumZxZVFREXfeeScrV65k586dpKWl8Zvf/IYuXbowevToer4sH3fWnyA8AQ7vgJUv1O8crumgftbvzJxbWMrs/23ivCeX8lHVH+/L+ifx1YwRPDi2D3ERzWfVydWDk4kODWDXwZImX3DpdBq8U1WjcPVgvSnV1YV9E/GzwY978tl10AsbnHpR2uYcDhWXExcRxNldm2YzSml+6pywjBs3jieeeILZs2czYMAA1q9fz8KFC92FuFlZWezfX/MPeXp6OsuXLz/udJDdbmfDhg1cdtlldOvWjRtvvJHU1FS++eYbgoKa6TBkUASMesC8vuxxKDx1wXINBfthxzLzet8rT36sBxWUVvDkl+mMfHwJb6zYRaXT4Oxubfjk1uE8c81AUprhJ/bQQH9uGJYCwAtLtmE0tA7JQt9tO8iew0eJCPbnwj7HH82UE4sND+LMLrEA7g7NzYUrkf1dajv8VdckPqJelZpTp05l6tSpx73veIWy3bt3P+Ef9pCQEL744ov6hNG09RsHa/4Be7+HtL/C2Odr/1jXzszJQyCmo+diPIHSCgf/XrmL5xZv5XCJucS3f3I0d4/pzrDOsV6Px9uuH5rCi0u389O+Ar7JzOPsbk3zE+jbVZ1txw5o22Triqx2Sb9EvsnM4+Mf9zHlnC5Wh9MosvNLWVpV13SlmgiKD1HqbBU/P7iwqh/L+jdh79raP9Y1HeTl0RVH1RTCuU8s4aFPN3O4pIJObcKYf91pfPjHYS0iWQFoFRbINYPNluwvLNlmcTT1c6i4nC9/MovnVaNQf6N7JxBgt7Elu5DMnEKrw2kU/11n1jWdntKKTm3CrQ5HxE0Ji5XaDYL+15jXP78bnM5TPyZ3C2RvAD9/r+3MbBgGX/6UzZh5y7jrvQ3syy8lITKYR3/Xly+nn82YPoktrkfDTWd1xN/PxortB1m/+4jV4dTZBz/spdzhpE/bSPq0VUOw+ooODXTXeHzcDKaFDMNw9165Up1txccoYbHaqAcgMNzcE2jju6c+3rXRYZfzIczz3WF35hXzuxe+4+Z/rSUzt4iokADuvagHS+4cybjT27fY+e2k6BB3b4r5TWyUxTAM9/4w4/Sm1GCX9jdb9X/y474mXdMEsGbnYXYeLCEs0M7FfVXXJL6lZb7b+JKIBHPVEMBX90NZ0YmPdTphQ1VS08/z00GGYfCnd39kXdYRggP8+OPIziy76xxuPruzah6AW0aYS5y/+Dmbrbkn+X/zMet3HyE9p5Agfz8uG6CGYA01qlc8Qf5+bM8r5uf9TaDr9kksqEpkL+mXRFiQ7zWjlJZNCYsvGDoFWnWEwv2wfO6Jj9u9CvKzIDACul3o8bAWp+eydtdhggP8WHT7CO4a04OokKbdS6UxdYmL4Pxe8RgGvLSs6YyyuN6ULu6bqP/PRhAe5M+5VVsaNOUdnAtLK/hsoxn/Vaer2FZ8jxIWX+AfBKMfNq9/9ywc2nH841zFtr0ug8BQj4bkdBo8/kUGADcM60hyjGefr6maPNJs1//BD3ubRIv24rJKd6MzFds2Hte00MdNeFro0w37OVrhoFObME5r38rqcESOoYTFV3S/CDqNBEcZfPnnY++vLIefPjCve2F10Kcb97N5fwERQf7uqQ851mntWzGkYwwVDoNXvjlBoulDPt2wn+JyBx1jwxjcMcbqcJqNc7rHERZoZ++Ro/zQBIuwobr3ijY6FF+lhMVX2Gww5m9gs5tt97cvqXn/1kVQesTskNvxbI+GUulwMneRObpy89mdiA4N9OjzNXWuUZb/rM7iSEm5xdGcnKv3it6UGldIoJ3ze5nNM5viDs5bcwtZl3UEu5+Ny09TXZP4JiUsviSuJ5x+k3l94UxwVFbf5+69cgX4ebbg9b21e9iRV0zrsEAmDvd+Y7qmZkS3NvRMjKSk3MEbK3ZZHc4JZeZUvyn9LlVvSo3NvVpow74mt8+Ua6PDc7rHNautNKR5UcLia86ZCSExkPszrP2neVtpPqRX7ezs4Z2ZSyscPJ2WCcAfz+lCuFYKnJLNZnOPsrz23U6Oljssjuj4XMW25/bQm5InnNW1DZHB/uQWlrFm5yGrw6m1CoeT/64zE5arBqnYVnyXEhZfE9IKzr3PvP71Q1ByCH7+yKxtadMDEvp59OnfXJXF/vxSEqOCuXZIe48+V3NyUZ8EkmNCOFRc7q4F8CVllQ7er9p992oV23pEoL8fY/okAE1rB+fFW3LJKyonNjyQc6pWO4n4IiUsvih1IsT3MWtWFj/itZ2Zi8oqeX7xVgCmnddVvVbqwN/ux81nm6MsLy3bToWjFl2Lveirn3M5VFxOfGQQI5ro3kdNgWta6PNN2VT62M/AibxTNR10+WntCGihjSCladBPpy/ys8OYOeb171+BncvN6x5eHfTP5Ts4WFxOx9gwfqdNz+rsytR2xIYHsvfIUT7Z4FufsF3FtlemJrfY7sTeMLRTa1qHBXKouJzvth20OpxTyi0sZXF6LqCNDsX36S+Xr+p4NvS8zNyVGQPaD4Noz03RHCkp56Vl2wG4/fxu+qRVD8EBdiaeaRYpv7BkG04fKbzcc7iE5VvzAHN1kHiOv92Pi6pa2jeFaaEP1u3F4TQY2D6arvERVocjclJ6V/JlFzwE9iDzuoeLbecv3U5hWSU9EiK4RHuI1Nt1Z3QgPMifjJwi9ydXq737/R4MA4Z1bk371moA6GmX9DN/fxb+lE1ZpW8WYEPVnlLfa08paTqUsPiyVh3gt/Nh0O+h/9Uee5rcglJe+85senbn6O74+ak/R31FhQRw7RnmSNgLPrAposNZvfuuOtt6x+kpMcRHBlFYWsmyjDyrwzmhdVlH2HagmJAAOxf304cU8X1KWHxdn8vhkqcgIMRjT/Hs4q2UVjg5rX20e08Uqb8bz+xIoN2P73cdtnx56zeZB9iXX0pUSACjeydYGktL4edn45J+1a36fZVrx+6L+iYSEaw9pcT3KWFp4XYfKuGt1WZB5p2je6j7aSOIiwx2Fy3Pt3iUxTXk/9uBbbXqy4tcq4W+2pzjk315issq3YXh6r0iTYUSlhZu3leZVDgMzuoay9DOra0Op9m4+exO2GyQtiWXLdkFlsSQV1TGop9zAE0HeVv/dlEkx4RQUu7g6y2+Ucv0S59tNPeUSmkdqj2lpMlQwtKCZeYU8sEPZg+GOy7obnE0zUvH2DAu6mPWBby4dLslMXywbi8VDoP+7aLomRhpSQwtlc3m29NCrlb8V2pPKWlClLC0YHMXZeA0YHTvePonR1sdTrNzywizkdxHP+5j96ESrz63YRgscO2+q9EVS1xalbB8nZ5LYWmFxdFU236giNU7D+Fng9+dpukgaTqUsLRQG/Yc4fNN2dhsGl3xlL7tojiraywOp8E/vvHuKMu6rMNszS0iJMDOZVX1FOJdPRMj6NwmjPJKp3tqzhe8t9YcXRnRrQ0JUdpTSpoOJSwt1BNfZgBmMaYaRnnO5KpRlrfX7CavqMxrz/v2anN05eJ+WgFiFZvN9osdnPdbHI2p0uF0JyxqIihNjRKWFmjl9oMsyzhAgN3G7aO6WR1Osza0c2v6t4uirNLJ69/t9MpzFpZWuN8gtdGhtVx1LMsyDnCkpNziaGBZ5gFyC8uICQvkvJ7xVocjUidKWFoYwzB44ot0AK4+vT3JMep86kk2m43JI81Rlte/20lRWaXHn/OTDfs5WuGgU5swUju08vjzyYl1iQunZ2IklU6DhZuyrQ6Hd9aYoytjB7Ql0F9//qVp0U9sC7Mk/QDf7zpMcIAft57bxepwWoTzeyXQKTaMgtJK3q7qeeNJb1c1BLv6dK0A8QWX9q/aW8jiDTEPFpXx1Wazluaq01VsK02PEpYWxOk0eKxqdOX6YSnERargzhvsfjb+MKITAC9/s92j+8tsyS7gx91H8PezcblWgPgE12qhFdsOcqDQe3VMv/bBD3updBr0axdFjwQtc5emRwlLC/Lpxv1s3l9ARJA/t5zd2epwWpSxA9sSHxlETkEZ//vBc5+0F1SNrpzfK57Y8CCPPY/UXnJMKAOSo3Ea8Pkma4pvf7nRoYptpalSwtJCVDqczF1krgyadHYnWoUFWhxRyxLkb+em4eYoy/xl23A4jUZ/jtIKBx/8sBdQ7xVf49rB2aomchv25JORU0SQv5975ZJIU6OEpYX477o97MgrJiYskN8P72h1OC3SNUPaExnsz/YDxSz6ufELML/8OYcjJRUkRgVzdtc2jX5+qb9L+iVhs8GanYfZd+So15/f1UTwwj4JRIVombs0TUpYWoDSCgdPf5UJwB9HdiY8yN/iiFqm8CB/rh+WAsALS7ZhGI07yrJgjVnQe+WgZOx+Krb1JQlRwZyeYu7Z86mXe7IcLXfw8XrXRocaeZOmSwlLC/CfVVnsyy8lMSqY687oYHU4LdoNw1IIDvDjxz35rNh2sNHOu/tQCd9uPYjNBlemqtjWF1U3kfPutNDCn/ZTWFZJu1YhnNFJG5xK06WEpZkrLqvkucVbAbjtvK4EB9gtjqhlax0e5P6U+8LSbY12XldB5fAuseqt46Mu7JOAnw1+3JPProPFXnteV++VK1OT8dPImzRhSliauX9+u4ODxeWktA7lCn3y9gmTzuqE3c/GN5l5bNqb3+DzVTqc7t13x6nY1mfFhgdxZpdYwHut+rMOlrBiuznydsUg/f5L06aEpRk7UlLOi8vMTfduP78bAXb9d/uC5JhQLq1aNdIYoyzLMg+QXVBKq9AAzu+lduu+zNWTxVurhd5bWz3y1jY6xCvPKeIpegdrxl5ctp3C0kp6JES4/1CKb7ilql3/5xv3syOvYdMDrt4rvx3YjiB/Tfn5stG9Ewiw29iSXUhmTqFHn8vhNHhXGx1KM6KEpZnKLSzln9/uAOCOC7pr7trH9EiI5NwecTgNeKlqFKw+cgtLSducC2g6qCmICg1gRDdzyfnHHp4WWr41j/35pUSFaORNmgclLM3Uc19vpbTCycD20ZzXM87qcOQ4XJsi/nftHnILSut1jvfXme3WB7aPpntCRGOGJx7i2sH5kx/3NfrS9l9yFWKPHZCkYntpFpSwNEO7D5Xwn6pN9u4c3V0b4Pmo01NiGNShFeUOJ69UjYbVhWEYvPOLjQ6laRjVK54gfz+25xXz074CjzzH4eJyFv1kbnR4paaDpJlQwtIMPZ2WSYXDYHiXWIZ1jrU6HDkJ1yjLmyuzyD9aUafHrtl5mO15xYQG2rlYNUpNRniQv3vU01M7OP9v/V7KHU56J0XSp22UR55DxNuUsDQzW3MLeX+dWWh3x+juFkcjp3JO9zi6xYdTVFbJm6t21emxb1d1tr20X5K6Fzcxl7qnhfZ7ZFrone9VbCvNjxKWZmbuogycBozuHc+A5Girw5FT8POzccsIc5Tl1eU7Ka1w1OpxBaUVfLbRLNocN1hvSk3NOT3iCAu0s/fIUX7YfaRRz71pbz4/7y8g0O7HbwZo5E2aDyUszcjGPfl8tjEbmw3+dIFGV5qKS/sn0TY6hLyiMt6rWoZ6Kh+t30dphZNu8eEMVGLa5AQH2N0rdxq7J4ur2PaC3vFEh2pXdmk+lLA0I098mQ7Abwe0pVu8Vow0FQF2PyadZe6g/dKy7VQ6nKd8jKv3ylWDklVU3US59hb6dMN+HM7GmRYqrXDw4Q97AU0HSfOjhKWZWLX9IEszDuDvZ2P6qG5WhyN1NO709sSEBZJ1qITPNmWf9NhNe/PZuDefALuNy09Tu/Wm6qyubYgM9ie3sIzVOw41yjm//DmHgtJKkqKC3dsAiDQXSliaAcMwePwLc3Tl6sHJtG+tze+ampBAOzcMSwHghSXbTlqIWT3kn0BMmIb8m6pAfz8u7GNu0dBYOzi/W/WzccWgZOxqFinNjBKWZmBJ+gG+33WYIH8/bj23q9XhSD1NGNqB0EA7m/cXsDTjwHGP+eWQ/zgN+Td5l/Q3E5bPN2VTUYupwJPZc7iE5VvzALhSG51KM6SEpYlzOqtHV24YlkJ8ZLDFEUl9RYcGcs3g9gDMP8GmiAs3ZVNQWknb6BCGa8i/yRvaqTWtwwI5VFzOd9sONuhc/127F8OAYZ1bkxyjUVZpfpSwNHGfbdrPz/sLCA/ydy+PlabrprM6EmC3sXL7IdZlHT7mflfvlasGJWt/qGbA3+7HRX3NUZaGrBZyOg3eXVtdiC3SHClhacIqHU7mfpkBwKSzOtFK9QxNXmJUCGMHtAVg/pKaoyw784pZuf0QNhtcOUhD/s2Fa7XQFz9lU1ZZuz48v7Zi+0H2HD5KRLA/Y/okNGZ4Ij5DCUsT9v66vWzPKyYmLJAbq5bFStP3hxGdsNnMFR9bcwvdt7uKbc/u2oak6BCrwpNGNqhDKxIigyksrWRZRl69zuH62bisvzY6lOZLCUsTVVbpYN5X5ujKH0d2Vmv2ZqRLXAQXVDUVm790O2COpr1b1VROGx02L35+Ni7uV/9pofySCj6vWgo/Tj8b0owpYWmi/rMqi335pSREBnPdGR2sDkcamase6cMf9rLvyFEWpx/gQGEZrcMCOa9nvMXRSWNzTQst+jmHkvLKOj32ow37KK900iMhgr7a6FCaMSUsTVBxWSXPLd4KwG3nddUQcDM0sH0rhnZqTaXT4B/f7HB3tv1dajsC/fVr29z0bxdFckwIRyscfL0lt06PdfVeuVJdj6WZ01++Jui173aSV1ROh9ahKr5sxiaPNEdZ3lqdxeJ0801MK0CaJ5vN5t7BuS7TQpv3F7Bhj9n1eKw2OpRmrl4Jy3PPPUdKSgrBwcEMGTKE1atXn/DYkSNHYrPZjrlcfPHF7mMMw2D27NkkJiYSEhLCqFGjyMzMrE9ozV5+SYW7R8eM87sRYFfO2Vyd1TWW3kmRHK1w4HAaDOrQii5x4VaHJR7imhZanH6AwtKKWj3GVWw7qmc8rcODPBabiC+o87vdggULmDFjBvfffz/r1q2jf//+jB49mtzc4w9jvv/+++zfv9992bRpE3a7nSuvvNJ9zGOPPcYzzzzD/PnzWbVqFWFhYYwePZrS0tL6v7Jm6sVl2ygsraRHQoT7E5k0TzabrUZvHRVUNm89EiLo3CaM8koni37OOeXxZZXa6FBaljonLHPnzmXSpElMnDiRXr16MX/+fEJDQ3n11VePe3xMTAwJCQnuy6JFiwgNDXUnLIZhMG/ePP785z/zm9/8hn79+vHGG2+wb98+Pvzwwwa9uOYmt7CUf367E4A/XdBdjcNagIv6JrpHVlwrSaR5stls7lGW2kwLpW3O5XBJBfGRQZzVVV2PpfmrU8JSXl7O2rVrGTVqVPUJ/PwYNWoUK1asqNU5XnnlFa6++mrCwsIA2LFjB9nZ2TXOGRUVxZAhQ2p9zpbi+cXbOFrhYEByNKN6xlkdjniB3c/Ge5OH8dWMEYQGaul6c3dJ1ajpN5l5HC4uP+mxrumgK1Lb4a+pYWkB6vRTnpeXh8PhID6+5rLK+Ph4srOzT/n41atXs2nTJm666Sb3ba7H1eWcZWVlFBQU1Lg0d3sOl/Dmql0A3DW6u1YDiDRDXeLC6ZUYSaXTYOFPJ/6buj//KMuqNsi8MlXTQdIyeDUtf+WVV+jbty+DBw9u0HnmzJlDVFSU+5Kc3Px/YZ/+KpMKh8GZXVozTJveiTRbrh2cP9lw4mmh99ftxWnA4I4xpMSGeSs0EUvVKWGJjY3FbreTk1OzICwnJ4eEhJPvX1FcXMzbb7/NjTfeWON21+Pqcs6ZM2eSn5/vvuzevbsuL6PJ2ZpbyH/XmV1O7xzdw+JoRMSTXMX0K7YdJLfw2IUHTqfhng5Ssa20JHVKWAIDA0lNTSUtLc19m9PpJC0tjaFDh570se+++y5lZWVcd911NW7v2LEjCQkJNc5ZUFDAqlWrTnjOoKAgIiMja1yas7mLMnAacEGveAYkR1sdjoh4UHJMKAOSo3Ea8PnGY6eFVu88xK6DJYQF2rmorzY6lJajzlNCM2bM4OWXX+b1119n8+bNTJ48meLiYiZOnAjAhAkTmDlz5jGPe+WVVxg7diytW7eucbvNZmP69Ok89NBDfPTRR2zcuJEJEyaQlJTE2LFj6/eqmpGNe/L5bGM2Npu5MkhEmr+TrRZyja5c2j9JhdjSotT5p33cuHEcOHCA2bNnk52dzYABA1i4cKG7aDYrKws/v5p5UHp6OsuXL+fLL7887jnvuusuiouLufnmmzly5AjDhw9n4cKFBAcH1+MlNS9//9psoDd2QFu6J0RYHI2IeMPFfRN56NOf+X7XYfYdOerenbuwtILPNu4H4Cr15ZEWxmYYhmF1EA1VUFBAVFQU+fn5zWp6yDAMBj64iCMlFXw09Uz6tYu2OiQR8ZKrXlzB6h2HuO+inkw6uxNgbtMw8/2NdIkLZ9HtZ2u1oDR5dXn/1uJ9H5ZbWMaRkgrsfja6xWt0RaQlcU8L/WK1UHWxbTslK9LiKGHxYenZhQCktA7VjswiLcyFfRKw+9nYsCefnXnFZOYU8kPWEex+Nn47UJueSsujii0flpFjJiyqXRFpeWLDgxjWuTXfZObxyYZ95B81N0Q8t0ccbSK00aG0PEpYfJhrhEXTQSIt06X9k/gmM4//rd/H4RKzVb96r0hLpSkhH+YeYVHCItIije6VQIDdRmZuEXlF5bSJCOKc7m2sDkvEEkpYfJTTaZCRUwRoSkikpYoKDWBEt+oE5fLT2mqjQ2mx9JPvo3YfLuFohYNAfz86tNZeISItlWu1EGijQ2nZVMPio1z1K13jwrH7afmiSEt1Qa8EzuzSmk6x4XSJC7c6HBHLKGHxUapfERGAkEA7b950htVhiFhOU0I+Kr2qfqWb6ldERESUsPiq9OwCQAW3IiIioITFJ5VXOtl+oBjQlJCIiAgoYfFJO/KKqXQaRAT5kxilHatFRESUsPig9KqC224JEdrgTEREBCUsPilDLflFRERqUMLig7ZUJSw9VHArIiICKGHxSa4eLBphERERMSlh8TEl5ZVkHSoBoFu8ulqKiIiAEhafk1nVMC42PIjW4UEWRyMiIuIblLD4GNceQt0TNLoiIiLiooTFx6S79xCKtDgSERER36GExce4Nz3UCIuIiIibEhYfk64eLCIiIsdQwuJDDheXk1tYBkBXJSwiIiJuSlh8iKt+pV2rEMKD/C2ORkRExHcoYfEhrvoVdbgVERGpSQmLD1H9ioiIyPEpYfEh1SuElLCIiIj8khIWH2EYhkZYRERETkAJi4/ILiiloLQSu5+NTm3CrA5HRETEpyhh8RGu0ZVOsWEE+dstjkZERMS3KGHxEa76lW6qXxERETmGEhYfkZ5t7tLcXfUrIiIix1DC4iPcIyxKWERERI6hhMUHOJyGmsaJiIichBIWH5B1qISySifBAX4kx4RaHY6IiIjPUcLiA1wrhLrGRWD3s1kcjYiIiO9RwuIDVL8iIiJyckpYfEC6uyV/uMWRiIiI+CYlLD7ANSXUPSHS4khERER8kxIWi5VVOtiRVwyoB4uIiMiJKGGx2PYDxTicBpHB/sRHBlkdjoiIiE9SwmKxDHf9SgQ2m1YIiYiIHI8SFottydYKIRERkVNRwmKxjGx1uBURETkVJSwWS1cPFhERkVNSwmKhorJK9hw+CihhERERORklLBbKrBpdiYsIolVYoMXRiIiI+C4lLBaqbhin0RUREZGTUcJiIXdLfk0HiYiInJQSFgu5Nz3UCIuIiMhJKWGxUHp2EaARFhERkVNRwmKRg0Vl5BWVAdA1Xrs0i4iInIwSFou46lfax4QSGuhvcTQiIiK+TQmLRTK0QkhERKTWlLBYJD1H9SsiIiK1Va+E5bnnniMlJYXg4GCGDBnC6tWrT3r8kSNHmDJlComJiQQFBdGtWzc+++wz9/0PPPAANputxqVHjx71Ca3J0AohERGR2qtz8cSCBQuYMWMG8+fPZ8iQIcybN4/Ro0eTnp5OXFzcMceXl5dz/vnnExcXx3vvvUfbtm3ZtWsX0dHRNY7r3bs3X331VXVg/s23rsMwjOopIY2wiIiInFKds4K5c+cyadIkJk6cCMD8+fP59NNPefXVV7nnnnuOOf7VV1/l0KFDfPfddwQEBACQkpJybCD+/iQkJNQ1nCZpX34phWWV+PvZ6BgbZnU4IiIiPq9OU0Ll5eWsXbuWUaNGVZ/Az49Ro0axYsWK4z7mo48+YujQoUyZMoX4+Hj69OnDI488gsPhqHFcZmYmSUlJdOrUiWuvvZasrKwTxlFWVkZBQUGNS1PiGl3p3CacQH+VEYmIiJxKnd4t8/LycDgcxMfH17g9Pj6e7Ozs4z5m+/btvPfeezgcDj777DNmzZrFk08+yUMPPeQ+ZsiQIbz22mssXLiQF154gR07dnDWWWdRWFh43HPOmTOHqKgo9yU5ObkuL8Ny6apfERERqROPF4o4nU7i4uJ46aWXsNvtpKamsnfvXh5//HHuv/9+AC688EL38f369WPIkCF06NCBd955hxtvvPGYc86cOZMZM2a4vy4oKGhSSUt1/YoaxomIiNRGnRKW2NhY7HY7OTk5NW7Pyck5Yf1JYmIiAQEB2O129209e/YkOzub8vJyAgMDj3lMdHQ03bp1Y+vWrcc9Z1BQEEFBQXUJ3ae4R1hUcCsiIlIrdZoSCgwMJDU1lbS0NPdtTqeTtLQ0hg4detzHnHnmmWzduhWn0+m+LSMjg8TExOMmKwBFRUVs27aNxMTEuoTXJFQ6nGTmVvVg0ZSQiIhIrdS54nPGjBm8/PLLvP7662zevJnJkydTXFzsXjU0YcIEZs6c6T5+8uTJHDp0iGnTppGRkcGnn37KI488wpQpU9zH3HHHHSxdupSdO3fy3Xff8dvf/ha73c4111zTCC/Rt+w6VEJ5pZOQADvJrUKtDkdERKRJqHMNy7hx4zhw4ACzZ88mOzubAQMGsHDhQnchblZWFn5+1XlQcnIyX3zxBbfffjv9+vWjbdu2TJs2jbvvvtt9zJ49e7jmmms4ePAgbdq0Yfjw4axcuZI2bdo0wkv0La76lW7x4fj52SyORkREpGmwGYZhWB1EQxUUFBAVFUV+fj6RkZFWh3NS877KYN5XmVyZ2o7Hr+xvdTgiIiKWqcv7t5qAeJmrJb/qV0RERGpPCYuXbcnWCiEREZG6UsLiRaUVDnbmFQPQQyMsIiIitaaExYu2HSjCaUB0aABtIppuHxkRERFvU8LiRRm/aBhns2mFkIiISG0pYfGiLe6W/JoOEhERqQslLF7k7sGi+hUREZE6UcLiRRk5Zkt+FdyKiIjUjRIWLyksrWDvkaMAdItTwiIiIlIXSli8xDW6khAZTFRogMXRiIiINC1KWLwkXfUrIiIi9aaExUvcLfnjwy2OREREpOlRwuIlrhGW7gm+vTmjiIiIL1LC4iXVIyyaEhIREakrJSxekFdUxsHicmw26BKnKSEREZG6UsLiBa7poA4xoYQE2i2ORkREpOlRwuIF7hVCmg4SERGpFyUsXuCqX1GHWxERkfpRwuIF6TnqwSIiItIQSlg8zDAM96aHWiEkIiJSP0pYPGzP4aMUlzsIsNtIiQ2zOhwREZEmSQmLh7nqVzq3CSfArm+3iIhIfegd1MNc9SvdVb8iIiJSb0pYPCxDS5pFREQaTAmLh6XnFAEquBUREWkIJSweVOFwsi23KmHRlJCIiEi9KWHxoF0Hiyl3OAkLtNM2OsTqcERERJosJSwelJ5tjq50jY/Az89mcTQiIiJNlxIWD3KvEFL9ioiISIMoYfGg9OwCQC35RUREGkoJiwdlaIWQiIhIo1DC4iGlFQ52HiwGtEJIRESkoZSweMjW3CIMA2LCAokND7Q6HBERkSZNCYuHpLs73IZjs2mFkIiISEMoYfEQrRASERFpPEpYPMQ9wqL6FRERkQZTwuIhGVUjLD2UsIiIiDSYEhYPyD9awf78UsDscisiIiINo4TFAzKrRleSooKJDA6wOBoREZGmTwmLB2xR/YqIiEijUsLiARlaISQiItKolLB4gGuFkDrcioiINA4lLI3MMAz3CEs3jbCIiIg0CiUsjexAURmHSyrws0GXuHCrwxEREWkWlLA0Mtd0UErrMIID7BZHIyIi0jwoYWlk1XsIaTpIRESksShhaWTuFUIquBUREWk0SlgaWXpOEaCERUREpDEpYWlETqfh7nKrKSEREZHGo4SlEe05fJSScgeBdj9SWodaHY6IiEizoYSlEaVXja50jgvH365vrYiISGPRu2ojchXc9lD9ioiISKNSwtKItKRZRETEM5SwNKLqJc3qcCsiItKYlLA0kgqHk20HzCXNGmERERFpXPVKWJ577jlSUlIIDg5myJAhrF69+qTHHzlyhClTppCYmEhQUBDdunXjs88+a9A5fc2OvGIqHAbhQf60jQ6xOhwREZFmpc4Jy4IFC5gxYwb3338/69ato3///owePZrc3NzjHl9eXs7555/Pzp07ee+990hPT+fll1+mbdu29T6nL6quXwnHZrNZHI2IiEjzUueEZe7cuUyaNImJEyfSq1cv5s+fT2hoKK+++upxj3/11Vc5dOgQH374IWeeeSYpKSmMGDGC/v371/ucvkgt+UVERDynTglLeXk5a9euZdSoUdUn8PNj1KhRrFix4riP+eijjxg6dChTpkwhPj6ePn368Mgjj+BwOOp9zrKyMgoKCmpcrLZFK4REREQ8pk4JS15eHg6Hg/j4+Bq3x8fHk52dfdzHbN++nffeew+Hw8Fnn33GrFmzePLJJ3nooYfqfc45c+YQFRXlviQnJ9flZXiEe4RFCYuIiEij8/gqIafTSVxcHC+99BKpqamMGzeO++67j/nz59f7nDNnziQ/P9992b17dyNGXHcl5ZVkHSoBoJumhERERBqdf10Ojo2NxW63k5OTU+P2nJwcEhISjvuYxMREAgICsNvt7tt69uxJdnY25eXl9TpnUFAQQUFBdQndo7bmFmEYEBseSGy478QlIiLSXNRphCUwMJDU1FTS0tLctzmdTtLS0hg6dOhxH3PmmWeydetWnE6n+7aMjAwSExMJDAys1zl9jTrcioiIeFadp4RmzJjByy+/zOuvv87mzZuZPHkyxcXFTJw4EYAJEyYwc+ZM9/GTJ0/m0KFDTJs2jYyMDD799FMeeeQRpkyZUutz+jolLCIiIp5VpykhgHHjxnHgwAFmz55NdnY2AwYMYOHChe6i2aysLPz8qvOg5ORkvvjiC26//Xb69etH27ZtmTZtGnfffXetz+nr0rWkWURExKNshmEYVgfRUAUFBURFRZGfn09kZKTXn3/II1+RU1DGfycPI7VDK68/v4iISFNUl/dv7SXUQEdKyskpKAPMLrciIiLS+JSwNFBGjrnhYdvoECKCAyyORkREpHlSwtJA6dlml13Vr4iIiHiOEpYGchXcaoWQiIiI5yhhaaCMbHNKqHuC6ldEREQ8RQlLAxiGUb2kOd77q5NERERaCiUsDZBbWEb+0QrsfjY6tQmzOhwREZFmSwlLA2yp6nCb0jqU4AD7KY4WERGR+lLC0gAZ2epwKyIi4g1KWBpAK4RERES8QwlLA2RUJSw9NMIiIiLiUUpY6snpNNwJi0ZYREREPEsJSz1lHSqhtMJJoL8fHVprhZCIiIgnKWGpJ1f9Ste4cOx+NoujERERad6UsNSTVgiJiIh4j7/VATRV1R1ulbCIiDidTsrLy60OQ3xQQEAAdnvDe5UpYamn9KoRlm4aYRGRFq68vJwdO3bgdDqtDkV8VHR0NAkJCdhs9S+hUMJSD2WVDnbkFQMaYRGRls0wDPbv34/dbic5ORk/P1UaSDXDMCgpKSE3NxeAxMTEep9LCUs97MgrptJpEBHsT2JUsNXhiIhYprKykpKSEpKSkggNDbU6HPFBISEhAOTm5hIXF1fv6SGlwvXgmg7qHh/RoOEtEZGmzuFwABAYGGhxJOLLXMlsRUVFvc+hhKUe3A3jVL8iIgKgD29yUo3x86GEpR5+OcIiIiIinqeEpR606aGISNNmGAY333wzMTEx2Gw21q9fb3VITcYNN9zA2LFjvf68SljqqLiskt2HjgJqGici0lQtXLiQ1157jU8++YT9+/fTp08fq0OyxMiRI5k+fbrVYdSKVgnVUWZuEQBtIoKICVORmYhIU7Rt2zYSExMZNmzYCY8pLy9vssXEFRUVBAQEWB1Go9IISx1lqH5FRKRJu+GGG7j11lvJysrCZrORkpICmKMNU6dOZfr06cTGxjJ69GgAli5dyuDBgwkKCiIxMZF77rmHyspK9/lGjhzJrbfeyvTp02nVqhXx8fG8/PLLFBcXM3HiRCIiIujSpQuff/75SeN6/vnn6dq1K8HBwcTHx3PFFVe473M6nTz22GN06dKFoKAg2rdvz8MPPwzAzp07sdlsLFiwgBEjRhAcHMybb77JwYMHueaaa2jbti2hoaH07duXt956q8b3YenSpTz99NPYbDZsNhs7d+4E4KeffuKSSy4hMjKSiIgIzjrrLLZt21Yj3ieeeILExERat27NlClTGrQCqDY0wlJHW7JVvyIiciKGYXC0wmHJc4cE2Gu1GuXpp5+mc+fOvPTSS6xZs6ZGX5DXX3+dyZMn8+233wKwd+9eLrroIm644QbeeOMNtmzZwqRJkwgODuaBBx6o8bi77rqL1atXs2DBAiZPnswHH3zAb3/7W+69916eeuopxo8fT1ZW1nH71Xz//ffcdttt/Otf/2LYsGEcOnSIb775xn3/zJkzefnll3nqqacYPnw4+/fvZ8uWLTXOcc899/Dkk08ycOBAgoODKS0tJTU1lbvvvpvIyEg+/fRTxo8fT+fOnRk8eDBPP/00GRkZ9OnTh7/+9a8AtGnThr1793L22WczcuRIvv76ayIjI/n2229rJGmLFy8mMTGRxYsXs3XrVsaNG8eAAQOYNGlS7f6z6kEJSx25ljR3Twi3OBIREd9ztMJBr9lfWPLcP/91NKGBp35bi4qKIiIiArvdTkJCQo37unbtymOPPeb++r777iM5OZlnn30Wm81Gjx492LdvH3fffTezZ892d/bt378/f/7znwEzufjb3/5GbGys+w189uzZvPDCC2zYsIEzzjjjmJiysrIICwvjkksuISIigg4dOjBw4EAACgsLefrpp3n22We5/vrrAejcuTPDhw+vcY7p06dz+eWX17jtjjvucF+/9dZb+eKLL3jnnXcYPHgwUVFRBAYGEhoaWuP78NxzzxEVFcXbb7/tnlbq1q1bjfO2atWKZ599FrvdTo8ePbj44otJS0vzaMKiKaE60gohEZHmKzU1tcbXmzdvZujQoTVGbs4880yKiorYs2eP+7Z+/fq5r9vtdlq3bk3fvn3dt8XHxwO4W9T/2vnnn0+HDh3o1KkT48eP580336SkpMQdQ1lZGeedd95JYx80aFCNrx0OBw8++CB9+/YlJiaG8PBwvvjiC7Kysk56nvXr13PWWWedtAamd+/eNUamEhMTT/jaGotGWOrgUHE5BwrLACUsIiLHExJg5+e/jrbsuRsqLCysXo/79Zu7zWarcZsr4TnRBpERERGsW7eOJUuW8OWXXzJ79mweeOAB1qxZ425tX9fYH3/8cZ5++mnmzZtH3759CQsLY/r06afcVbs2z3e81+vpzS+VsNSBazooOSaEsCB960REfs1ms9VqWqap6NmzJ//9738xDMOddHz77bdERETQrl27Rn0uf39/Ro0axahRo7j//vuJjo7m66+/5qKLLiIkJIS0tDRuuummWp/v22+/5Te/+Q3XXXcdYCZLGRkZ9OrVy31MYGCge3sFl379+vH666/73EojTQnVgTrcioi0LH/84x/ZvXs3t956K1u2bOF///sf999/PzNmzGjUnak/+eQTnnnmGdavX8+uXbt44403cDqddO/eneDgYO6++27uuusu3njjDbZt28bKlSt55ZVXTnrOrl27smjRIr777js2b97MH/7wB3Jycmock5KSwqpVq9i5cyd5eXk4nU6mTp1KQUEBV199Nd9//z2ZmZn861//Ij09vdFeb30oYakD1a+IiLQsbdu25bPPPmP16tX079+fW265hRtvvNFdYNtYoqOjef/99zn33HPp2bMn8+fP56233qJ3794AzJo1iz/96U/Mnj2bnj17Mm7cuFPWjPz5z3/mtNNOY/To0YwcOZKEhIRjOtTecccd2O12evXqRZs2bcjKyqJ169Z8/fXXFBUVMWLECFJTU3n55ZctH22xGYZhWBpBIygoKCAqKor8/HwiIyM99jxXvPAd3+86zNNXD+A3A9p67HlERJqK0tJSduzYQceOHQkODrY6HPFRJ/o5qcv7t0ZYaskwDPcIi1ryi4iIeJcSllrKLiilsLQSfz8bnWLVg0VERMSblLDUkqvDbcfYMAL99W0TERHxJr3z1pJrD6Fumg4SERHxOiUsteSuX9EKIREREa9TwlJLGSq4FRERsYwSllpwOA0yc4oAjbCIiIhYQQlLLew6WExZpZPgAD+SY47dFlxEREQ8SwlLLbimg7rGRWD3s53iaBEREWlsSlhqIT3bnA5SS34REfEmm83Ghx9+6PHnSUlJYd68eR5/noZQwlILrhGWHiq4FRGRk2jsN/79+/dz4YUXNtr5mjIlLLWwJbsAUA8WEZGWqry8vNHO5XA4cDqdtTo2ISGBoKCgRnvupkwJyymUVjjYebAE0AohEZHmYuTIkUydOpWpU6cSFRVFbGwss2bNwrUfcEpKCg8++CATJkwgMjKSm2++GYDly5dz1llnERISQnJyMrfddhvFxcXuc+7atYvbb78dm82GzWbWPL722mtER0fz0Ucf0atXL4KCgsjKymLNmjWcf/75xMbGEhUVxYgRI1i3bl2NOH85JbRz505sNhvvv/8+55xzDqGhofTv358VK1bUeMzJYgTIzc3l0ksvJSQkhI4dO/Lmm2965Hvc2JSwnML2A8U4nAaRwf7ERyrLFRE5KcOA8mJrLlXJRm29/vrr+Pv7s3r1ap5++mnmzp3LP/7xD/f9TzzxBP379+eHH35g1qxZbNu2jTFjxvC73/2ODRs2sGDBApYvX87UqVMBeP/992nXrh1//etf2b9/P/v373efq6SkhEcffZR//OMf/PTTT8TFxVFYWMj111/P8uXLWblyJV27duWiiy6isLDwpHHfd9993HHHHaxfv55u3bpxzTXXUFlZCXDKGAFuuOEGdu/ezeLFi3nvvfd4/vnnyc3NrdP3zgr+Vgfg637ZMM6VLYuIyAlUlMAjSdY89737IDCs1ocnJyfz1FNPYbPZ6N69Oxs3buSpp55i0qRJAJx77rn86U9/ch9/0003ce211zJ9+nQAunbtyjPPPMOIESN44YUXiImJwW63ExERQUJCQo3nqqio4Pnnn6d///7u284999wax7z00ktER0ezdOlSLrnkkhPGfccdd3DxxRcD8Je//IXevXuzdetWevTowZw5c04aY1ZWFp9//jmrV6/m9NNPB+CVV16hZ8+etf6+WUUjLKeQrg63IiLN0hlnnFHjg+jQoUPJzMzE4XAAMGjQoBrH//jjj7z22muEh4e7L6NHj8bpdLJjx46TPldgYCD9+vWrcVtOTg6TJk2ia9euREVFERkZSVFREVlZWSc91y/Pk5iYCOAeITlVjJs3b8bf35/U1FT3OXr06EF0dPRJn9MXaITlFNKztYeQiEitBYSaIx1WPXcjCgurOVpTVFTEH/7wB2677bZjjm3fvv1JzxUSEnLMKP3111/PwYMHefrpp+nQoQNBQUEMHTr0lAW+AQEB7uuuc7qKeE8VY0ZGxknP7cuUsJyCK2FRDxYRkVqw2eo0LWOlVatW1fjaVUdit9uPe/xpp53Gzz//TJcuXU54zsDAQPcIzal8++23PP/881x00UUA7N69m7y8vFpGf3ynirFHjx5UVlaydu1a95RQeno6R44cadDzeoOmhE6isLSCvUeOAkpYRESam6ysLGbMmEF6ejpvvfUWf//735k2bdoJj7/77rv57rvvmDp1KuvXryczM5P//e9/NQpaU1JSWLZsGXv37j1l8tG1a1f+9a9/sXnzZlatWsW1115LSEhIg17TqWLs3r07Y8aM4Q9/+AOrVq1i7dq13HTTTQ1+Xm9QwnISBvDni3tyw7AUWoUFWh2OiIg0ogkTJnD06FEGDx7MlClTmDZtmnv58vH069ePpUuXkpGRwVlnncXAgQOZPXs2SUnVRcZ//etf2blzJ507d6ZNmzYnff5XXnmFw4cPc9pppzF+/Hhuu+024uLiGvSaahPjP//5T5KSkhgxYgSXX345N998c4Of1xtshlHHdWA+qKCggKioKPLz84mMjLQ6HBGRFqO0tJQdO3bQsWNHgoODrQ6n1kaOHMmAAQN8vh19c3Gin5O6vH/Xa4TlueeeIyUlheDgYIYMGcLq1atPeOxrr73mbqDjuvz6h/qGG2445pgxY8bUJzQRERFphupcdLtgwQJmzJjB/PnzGTJkCPPmzWP06NGkp6efcEgpMjKS9PR099fH62cyZswY/vnPf7q/VitiERERcalzwjJ37lwmTZrExIkTAZg/fz6ffvopr776Kvfcc89xH2Oz2Y5povNrQUFBpzxGRESkMSxZssTqEKSO6jQlVF5eztq1axk1alT1Cfz8GDVq1DF7GfxSUVERHTp0IDk5md/85jf89NNPxxyzZMkS4uLi6N69O5MnT+bgwYMnPF9ZWRkFBQU1LiIiItJ81SlhycvLw+FwEB8fX+P2+Ph4srOzj/uY7t278+qrr/K///2Pf//73zidToYNG8aePXvcx4wZM4Y33niDtLQ0Hn30UZYuXcqFF154wrXsc+bMISoqyn1JTk6uy8sQERGRJsbjjeOGDh3K0KFD3V8PGzaMnj178uKLL/Lggw8CcPXVV7vv79u3L/369aNz584sWbKE884775hzzpw5kxkzZri/LigoUNIiImKhZrDgVDzI1Ym3IeqUsMTGxmK328nJyalxe05OTq3rTwICAhg4cCBbt2494TGdOnUiNjaWrVu3HjdhCQoKUlGuiIgPCAgIwGazceDAAdq0aaNNYqUGwzAoLy/nwIED+Pn5ERhY/55mdUpYAgMDSU1NJS0tjbFjxwJm1pSWllaj09/JOBwONm7c6G5FfDx79uzh4MGD7k2dRETEN9ntdtq1a8eePXvYuXOn1eGIjwoNDaV9+/b4+dW/X22dp4RmzJjB9ddfz6BBgxg8eDDz5s2juLjYvWpowoQJtG3bljlz5gBm178zzjiDLl26cOTIER5//HF27drFTTfdBJgFuX/5y1/43e9+R0JCAtu2beOuu+6iS5cujB49ut4vTEREvCM8PJyuXbtSUVFhdSjig+x2O/7+/g0efatzwjJu3DgOHDjA7Nmzyc7OZsCAASxcuNBdiJuVlVUjgzp8+DCTJk0iOzubVq1akZqaynfffUevXr3cL2TDhg28/vrrHDlyhKSkJC644AIefPBBTfuIiDQRdrv9hJsGijQGteYXERERS3i8Nb+IiIiINylhEREREZ/n8T4s3uCa1VLHWxERkabD9b5dm+qUZpGwFBYWAqh5nIiISBNUWFhIVFTUSY9pFkW3TqeTffv2ERER0ehNi1xddHfv3t0iC3pb+usHfQ9a+usHfQ9a+usHfQ889foNw6CwsJCkpKRT9mhpFiMsfn5+tGvXzqPPERkZ2SJ/SF1a+usHfQ9a+usHfQ9a+usHfQ888fpPNbLioqJbERER8XlKWERERMTnKWE5haCgIO6///4W23W3pb9+0Pegpb9+0Pegpb9+0PfAF15/syi6FRERkeZNIywiIiLi85SwiIiIiM9TwiIiIiI+TwmLiIiI+DwlLKfw3HPPkZKSQnBwMEOGDGH16tVWh+QVc+bM4fTTTyciIoK4uDjGjh1Lenq61WFZ5m9/+xs2m43p06dbHYpX7d27l+uuu47WrVsTEhJC3759+f77760OyyscDgezZs2iY8eOhISE0LlzZx588MFa7XnSVC1btoxLL72UpKQkbDYbH374YY37DcNg9uzZJCYmEhISwqhRo8jMzLQmWA842euvqKjg7rvvpm/fvoSFhZGUlMSECRPYt2+fdQF7wKl+Bn7plltuwWazMW/ePK/EpoTlJBYsWMCMGTO4//77WbduHf3792f06NHk5uZaHZrHLV26lClTprBy5UoWLVpERUUFF1xwAcXFxVaH5nVr1qzhxRdfpF+/flaH4lWHDx/mzDPPJCAggM8//5yff/6ZJ598klatWlkdmlc8+uijvPDCCzz77LNs3ryZRx99lMcee4y///3vVofmMcXFxfTv35/nnnvuuPc/9thjPPPMM8yfP59Vq1YRFhbG6NGjKS0t9XKknnGy119SUsK6deuYNWsW69at4/333yc9PZ3LLrvMgkg951Q/Ay4ffPABK1euJCkpyUuRAYac0ODBg40pU6a4v3Y4HEZSUpIxZ84cC6OyRm5urgEYS5cutToUryosLDS6du1qLFq0yBgxYoQxbdo0q0PymrvvvtsYPny41WFY5uKLLzZ+//vf17jt8ssvN6699lqLIvIuwPjggw/cXzudTiMhIcF4/PHH3bcdOXLECAoKMt566y0LIvSsX7/+41m9erUBGLt27fJOUF52ou/Bnj17jLZt2xqbNm0yOnToYDz11FNeiUcjLCdQXl7O2rVrGTVqlPs2Pz8/Ro0axYoVKyyMzBr5+fkAxMTEWByJd02ZMoWLL764xs9BS/HRRx8xaNAgrrzySuLi4hg4cCAvv/yy1WF5zbBhw0hLSyMjIwOAH3/8keXLl3PhhRdaHJk1duzYQXZ2do3fhaioKIYMGdIi/yaC+XfRZrMRHR1tdShe43Q6GT9+PHfeeSe9e/f26nM3i80PPSEvLw+Hw0F8fHyN2+Pj49myZYtFUVnD6XQyffp0zjzzTPr06WN1OF7z9ttvs27dOtasWWN1KJbYvn07L7zwAjNmzODee+9lzZo13HbbbQQGBnL99ddbHZ7H3XPPPRQUFNCjRw/sdjsOh4OHH36Ya6+91urQLJGdnQ1w3L+JrvtaktLSUu6++26uueaaFrUZ4qOPPoq/vz+33Xab159bCYuc0pQpU9i0aRPLly+3OhSv2b17N9OmTWPRokUEBwdbHY4lnE4ngwYN4pFHHgFg4MCBbNq0ifnz57eIhOWdd97hzTff5D//+Q+9e/dm/fr1TJ8+naSkpBbx+uXEKioquOqqqzAMgxdeeMHqcLxm7dq1PP3006xbtw6bzeb159eU0AnExsZit9vJycmpcXtOTg4JCQkWReV9U6dO5ZNPPmHx4sW0a9fO6nC8Zu3ateTm5nLaaafh7++Pv78/S5cu5ZlnnsHf3x+Hw2F1iB6XmJhIr169atzWs2dPsrKyLIrIu+68807uuecerr76avr27cv48eO5/fbbmTNnjtWhWcL1d6+l/010JSu7du1i0aJFLWp05ZtvviE3N5f27du7/y7u2rWLP/3pT6SkpHj8+ZWwnEBgYCCpqamkpaW5b3M6naSlpTF06FALI/MOwzCYOnUqH3zwAV9//TUdO3a0OiSvOu+889i4cSPr1693XwYNGsS1117L+vXrsdvtVofocWeeeeYxS9kzMjLo0KGDRRF5V0lJCX5+Nf9E2u12nE6nRRFZq2PHjiQkJNT4m1hQUMCqVataxN9EqE5WMjMz+eqrr2jdurXVIXnV+PHj2bBhQ42/i0lJSdx555188cUXHn9+TQmdxIwZM7j++usZNGgQgwcPZt68eRQXFzNx4kSrQ/O4KVOm8J///If//e9/REREuOeoo6KiCAkJsTg6z4uIiDimXicsLIzWrVu3mDqe22+/nWHDhvHII49w1VVXsXr1al566SVeeuklq0PziksvvZSHH36Y9u3b07t3b3744Qfmzp3L73//e6tD85iioiK2bt3q/nrHjh2sX7+emJgY2rdvz/Tp03nooYfo2rUrHTt2ZNasWSQlJTF27Fjrgm5EJ3v9iYmJXHHFFaxbt45PPvkEh8Ph/rsYExNDYGCgVWE3qlP9DPw6SQsICCAhIYHu3bt7PjivrEVqwv7+978b7du3NwIDA43BgwcbK1eutDokrwCOe/nnP/9pdWiWaWnLmg3DMD7++GOjT58+RlBQkNGjRw/jpZdesjokrykoKDCmTZtmtG/f3ggODjY6depk3HfffUZZWZnVoXnM4sWLj/t7f/311xuGYS5tnjVrlhEfH28EBQUZ5513npGenm5t0I3oZK9/x44dJ/y7uHjxYqtDbzSn+hn4NW8ua7YZRjNu2ygiIiLNgmpYRERExOcpYRERERGfp4RFREREfJ4SFhEREfF5SlhERETE5ylhEREREZ+nhEVERER8nhIWERER8XlKWERERMTnKWERERERn6eERURERHyeEhYRERHxef8PXUJ+5e3H7T0AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(from_scratch_valid_acc, label='from scratch')\n",
        "plt.plot(pretrained_valid_acc, label='pretrained')\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of our model training, we compare both models, analyzing their respective performances and how they evolve across training epochs.\n",
        "\n",
        "**Pretrained Model (Top accuracy: 80%):**\n",
        "Initialized with weights learned from a vast amount of text data, the pretrained model begins with a higher accuracy compared to the second model. This initial advantage is expected since it carries knowledge from the pretrained weights. As the training progresses over multiple epochs, the accuracy of the model steadily improves, reaching a peak accuracy of 80%. This indicates that it has effectively leveraged the prior knowledge gained from pretraining, acquiring valuable features and representations from the large text corpus. This enhances its performance on the target task.\n",
        "\n",
        "**From Scratch Model (Top accuracy: 78%):**\n",
        "Conversely, the from scratch model starts with a lower accuracy compared to the pretrained model. This discrepancy arises from the fact that it begins with randomly initialized weights, devoid of any prior knowledge. As the training progresses, its accuracy improves, reaching a peak of 78%.\n",
        "\n",
        "**Interpretation:**\n",
        "The gap between the accuracy curves for both models clearly highlights the advantages of transfer learning using a pretrained model. The pretrained model consistently outperforms the from scratch model in terms of final accuracy. The higher initial accuracy reveals its capability to start with a head start in the fine-tuning task, as it has already acquired valuable features during pretraining, such as knowledge, semantics, and words polysemy. This demonstrates the importance of general natural language understanding.\n"
      ],
      "metadata": {
        "id": "lv3lkoFTkdIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict some data classification of the pretrained model\n",
        "def predict(path_data_test, path_labels_test=None):\n",
        "    model.eval()\n",
        "    data_loader = get_loader(\n",
        "        path_data_test,\n",
        "        path_labels_test,\n",
        "        token2ind=token2ind,\n",
        "        batch_size=1,\n",
        "        task='classification',\n",
        "    )\n",
        "    i= 0\n",
        "    for idx, data in enumerate(data_loader):\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask)\n",
        "        output = output[-1]\n",
        "        prediction = torch.argmax(output, dim=1)\n",
        "        ground_truth = data[1].item()\n",
        "\n",
        "        # print original text and it's prediction classification\n",
        "        if prediction == ground_truth:\n",
        "            prediction_text = f'\\033[92m{\"Positive\" if prediction == 1 else \"Negative\"}\\033[0m'  # Green\n",
        "            ground_truth_text = f'\\033[92m{\"Positive\" if ground_truth == 1 else \"Negative\"}\\033[0m'  # Green\n",
        "        else:\n",
        "            prediction_text = f'\\033[91m{\"Positive\" if prediction == 1 else \"Negative\"}\\033[0m'  # Red\n",
        "            ground_truth_text = f'\\033[91m{\"Positive\" if ground_truth == 1 else \"Negative\"}\\033[0m'  # Red\n",
        "\n",
        "\n",
        "        # Print the information\n",
        "        print(s.decode_pieces([ind2token[ind.item()] for ind in input[1:]])) # original text decoded from tokens\n",
        "        print(\" --->\")\n",
        "        print(f'Predictions of the review: {prediction_text}')\n",
        "        print(f'Ground Truth review: {ground_truth_text}')\n",
        "        print('= = = = =\\n')\n",
        "\n",
        "        i +=1\n",
        "        if i == 10:\n",
        "            break\n"
      ],
      "metadata": {
        "id": "lKojhKULfS1n"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Evaluates the classification predictions of a pretrained model on a given test dataset. It prints the original text along with the model's prediction and the ground truth classification. The output is color-coded (green for correct predictions, red for incorrect predictions.__"
      ],
      "metadata": {
        "id": "6MV-HazllzKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict(path_data_valid, path_labels_valid)"
      ],
      "metadata": {
        "id": "DdXOSnzlBcvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3dd9a41-545f-453e-9a0e-ffd7f3957395"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce livres et une vrai drogue! la derniere fois je n' arrivais meme pas a m' arreter!A LIRE ABSOLUMENT!!!!!!!!!!!!!!!\n",
            " --->\n",
            "Predictions of the review: \u001b[91mNegative\u001b[0m\n",
            "Ground Truth review: \u001b[91mPositive\u001b[0m\n",
            "= = = = =\n",
            "\n",
            "Livre agréable et étonnant par sa façon d'abordé l'argetn. J'ai déja un fcp que j'achète à ma banque et j'ai réalisé pas mal d'économies sur la réduction des frais d'entrée ainsi que bien d'autres économies en appliquant les conseils donné dans ce livre. J'ai 2 enfants qui ont des livrets d'épargnes et que j'ai changé pour faire plus que essayer d'absorber l'inflation, maintenant ils créent des richesses.\n",
            " --->\n",
            "Predictions of the review: \u001b[91mNegative\u001b[0m\n",
            "Ground Truth review: \u001b[91mPositive\u001b[0m\n",
            "= = = = =\n",
            "\n",
            "Je ne crois pas avoir déjà lu un livre aussi beau. Je ne savais pas du tout à quoi m'attendre lorsque j'ai ouvert le premier volume, mais au bout de quelques pages, j'étais déjà plongée dans l'histoire. J'ai dévoré les trois tomes à la suite ! C'est le genre d'ouvrage qui vous habite, vous hante, et restera gravé en vous toute votre vie. Je me suis d'ailleurs tellement laissée emportée par cette histoire magnifique que je me suis trouvée à sangloter en m'imaginant faire face au même dilemme que Lyra à la fin du livre (je n'en dis pas plus pour ceux qui n'en sont pas encore arrivés là !). De plus, l'écriture est extrêmement raffinée. Bref, de la grande littérature, que je conseillerais cependant plutôt à des adolescents ou des adultes qu'à des enfants. Merci mille fois Mr Pullman !\n",
            " --->\n",
            "Predictions of the review: \u001b[91mNegative\u001b[0m\n",
            "Ground Truth review: \u001b[91mPositive\u001b[0m\n",
            "= = = = =\n",
            "\n",
            "Il y a ces livres épais qu'on finit trop vite tellement on est pris, et d'autres beaucoup plus courts mais qui nous paraissent une éternité à se terminer. 'Parce que je t'aime' fait partie de la seconde catégorie. Complètement invraisemblable, on arrive pas à rentrer une seconde dans l'histoire des personnages, trop happy end aussi, tout le monde s'aime, personne n'en veut à personne... J'ai toutefois mis une seconde étoile, pour l'histoire d'Evie, la seule à peu près touchante.\n",
            " --->\n",
            "Predictions of the review: \u001b[92mNegative\u001b[0m\n",
            "Ground Truth review: \u001b[92mNegative\u001b[0m\n",
            "= = = = =\n",
            "\n",
            "Je vais faire figure d'exception, mais je n'ai pas apprécié ce roman plein de longueurs et de caricatures. J'ai trouvé que la psychologie des personnages n'était pas assez approfondie et que l'histoire manquait cruellement de rythme. La lecture de ce qui est souvent considéré comme le \"chef d'oeuvre de Wilde\" me laisse un arrière goût d'ennui persistant, je retourne voir le fantôme de Canterville.\n",
            " --->\n",
            "Predictions of the review: \u001b[92mNegative\u001b[0m\n",
            "Ground Truth review: \u001b[92mNegative\u001b[0m\n",
            "= = = = =\n",
            "\n",
            "Absolument magnifique.Personellement j'ai commencé en voyant les films puis j'ai décidé de m'acheter les 3 livres.Malgré quelques lenteurs au début du livre,il raconte exactement le film mais avec beaucoup plus de détails ce qui permet au lecteur de comprendre enfin par exemple qui est Gollum.Toutes les scènes sont détaillés au moindre détail et c'est ce qui nous fait aimer cette lecture.Si vous avez aimé les films,vous aimerez ces livres...\n",
            " --->\n",
            "Predictions of the review: \u001b[92mPositive\u001b[0m\n",
            "Ground Truth review: \u001b[92mPositive\u001b[0m\n",
            "= = = = =\n",
            "\n",
            "Pour ceux qui ne sont pas trop accros de lecture, voici un livre que je vous conseille absolument, tout d'abord il est bien écrit, facile à lire et rédiger de façon qu'on a toujours envie d'en savoir plus au fil des pages, un conte où tout est féerique, et où les aventures de nos héros s'enchainent de page en page, où l'on a envie d'arriver au bout de l'ouvrage pour connaitre enfin la fin de cette agréable aventure à travers le rêve... Les personnages sont attachants, et c'est un conte qui ne fait pas du tout peur, à lire aux alentours de 11 ans et plus\n",
            " --->\n",
            "Predictions of the review: \u001b[92mPositive\u001b[0m\n",
            "Ground Truth review: \u001b[92mPositive\u001b[0m\n",
            "= = = = =\n",
            "\n",
            "Voilà un livre facile à lire contenant toutes les informations nécessaires pour nous motiver à utiliser CSS pour développer nos sites Web et qui nous explique comment l'utiliser. Par contre, je ne mets que 4 étoiles car je trouve son prix un peu exagéré. Ce genre d'ouvrage ne devrait pas dépasser 20 auros.\n",
            " --->\n",
            "Predictions of the review: \u001b[92mPositive\u001b[0m\n",
            "Ground Truth review: \u001b[92mPositive\u001b[0m\n",
            "= = = = =\n",
            "\n",
            "J'ai calé à la page 502... incapable d'aller plus loin.... lourd, pénible, décevant... des détails, des détails, des détails, mais en fait très peu d'actions... Non, franchement, je ne conseille vraiment pas !!\n",
            " --->\n",
            "Predictions of the review: \u001b[92mNegative\u001b[0m\n",
            "Ground Truth review: \u001b[92mNegative\u001b[0m\n",
            "= = = = =\n",
            "\n",
            "Si vous aimez les univers de magie, alors n'hésiter pas , vous ne le regretterez pas ! J'ai été littéralement transporté par ce livre qui allie action et amour dans un mélange de magie tout a fait prenant! D'autant plus qu'il se suit de 5 ouvrages différents qui nous laisse le tps d'en profiter au maximum. Mais attention ... si vous vous y accrocher, ne compter pas vous en défair! Sa deviendra une obscession jusqu'a avoir fini tte l'histoir! J'ai moi meme énormément apprécié le seigneur des anneaux. Si celui-ci n'est pas mieux, il est au moins aussi bien avec l'avantage d'etre plus facile à lire!\n",
            " --->\n",
            "Predictions of the review: \u001b[92mPositive\u001b[0m\n",
            "Ground Truth review: \u001b[92mPositive\u001b[0m\n",
            "= = = = =\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##__<center>END</center>__"
      ],
      "metadata": {
        "id": "DFNzIc4rmHtC"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f3cfdeab8dd8f9900bd16266619de191cf0f5e09365d74b1fba1714dce58066"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}